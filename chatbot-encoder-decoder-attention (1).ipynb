{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-22T10:40:49.843547Z","iopub.execute_input":"2023-09-22T10:40:49.843983Z","iopub.status.idle":"2023-09-22T10:40:49.859589Z","shell.execute_reply.started":"2023-09-22T10:40:49.843872Z","shell.execute_reply":"2023-09-22T10:40:49.858767Z"},"editable":false,"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/cleaned-data-for-the-chatbot-collected-from-movies/model_att29iter_expanded.data-00000-of-00001\n/kaggle/input/cleaned-data-for-the-chatbot-collected-from-movies/input3.csv\n/kaggle/input/cleaned-data-for-the-chatbot-collected-from-movies/model_att29iter_expanded.index\n/kaggle/input/cleaned-data-for-the-chatbot-collected-from-movies/dialogs_expanded.csv\n/kaggle/input/cleaned-data-for-the-chatbot-collected-from-movies/target3.csv\n/kaggle/input/glove6b50dtxt/glove.6B.50d.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"import re\nfrom nltk.corpus import stopwords\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\n\nfrom keras.layers import Input,Embedding,Bidirectional,LSTM,Dense,Concatenate\nfrom keras.models import Model","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:40:49.862208Z","iopub.execute_input":"2023-09-22T10:40:49.862736Z","iopub.status.idle":"2023-09-22T10:40:55.835324Z","shell.execute_reply.started":"2023-09-22T10:40:49.862699Z","shell.execute_reply":"2023-09-22T10:40:55.834461Z"},"editable":false,"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# loading The Dataset","metadata":{"editable":false}},{"cell_type":"code","source":"df= pd.read_csv('/kaggle/input/cleaned-data-for-the-chatbot-collected-from-movies/dialogs_expanded.csv', index_col=False)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:40:55.837549Z","iopub.execute_input":"2023-09-22T10:40:55.837922Z","iopub.status.idle":"2023-09-22T10:40:57.339347Z","shell.execute_reply.started":"2023-09-22T10:40:55.837884Z","shell.execute_reply":"2023-09-22T10:40:57.338579Z"},"editable":false,"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                           question  \\\n0           1  Well, I thought we'd start with pronunciation,...   \n1           2  Not the hacking and gagging and spitting part....   \n2           3  You're asking me out.  That's so cute. What's ...   \n3           4  No, no, it's my fault -- we didn't have a prop...   \n4           9     Gosh, if only we could find Kat a boyfriend...   \n\n                                              answer  \\\n0  Not the hacking and gagging and spitting part....   \n1  Okay... then how 'bout we try out some French ...   \n2                                         Forget it.   \n3                                           Cameron.   \n4                          Let me see what I can do.   \n\n                                     question_as_int  \\\n0  [54, 67, 74, 74, 12, 1, 40, 1, 82, 70, 77, 83,...   \n1  [45, 77, 82, 1, 82, 70, 67, 1, 70, 63, 65, 73,...   \n2  [56, 77, 83, 8, 80, 67, 1, 63, 81, 73, 71, 76,...   \n3  [45, 77, 12, 1, 76, 77, 12, 1, 71, 82, 8, 81, ...   \n4  [38, 77, 81, 70, 12, 1, 71, 68, 1, 77, 76, 74,...   \n\n                                       answer_as_int  question_len  answer_len  \n0  [45, 77, 82, 1, 82, 70, 67, 1, 70, 63, 65, 73,...            71          55  \n1  [46, 73, 63, 87, 14, 14, 14, 1, 82, 70, 67, 76...            55          73  \n2            [37, 77, 80, 69, 67, 82, 1, 71, 82, 14]            62          10  \n3                   [34, 63, 75, 67, 80, 77, 76, 14]            65           8  \n4  [43, 67, 82, 1, 75, 67, 1, 81, 67, 67, 1, 85, ...            46          25  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>question</th>\n      <th>answer</th>\n      <th>question_as_int</th>\n      <th>answer_as_int</th>\n      <th>question_len</th>\n      <th>answer_len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Well, I thought we'd start with pronunciation,...</td>\n      <td>Not the hacking and gagging and spitting part....</td>\n      <td>[54, 67, 74, 74, 12, 1, 40, 1, 82, 70, 77, 83,...</td>\n      <td>[45, 77, 82, 1, 82, 70, 67, 1, 70, 63, 65, 73,...</td>\n      <td>71</td>\n      <td>55</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Not the hacking and gagging and spitting part....</td>\n      <td>Okay... then how 'bout we try out some French ...</td>\n      <td>[45, 77, 82, 1, 82, 70, 67, 1, 70, 63, 65, 73,...</td>\n      <td>[46, 73, 63, 87, 14, 14, 14, 1, 82, 70, 67, 76...</td>\n      <td>55</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>You're asking me out.  That's so cute. What's ...</td>\n      <td>Forget it.</td>\n      <td>[56, 77, 83, 8, 80, 67, 1, 63, 81, 73, 71, 76,...</td>\n      <td>[37, 77, 80, 69, 67, 82, 1, 71, 82, 14]</td>\n      <td>62</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>No, no, it's my fault -- we didn't have a prop...</td>\n      <td>Cameron.</td>\n      <td>[45, 77, 12, 1, 76, 77, 12, 1, 71, 82, 8, 81, ...</td>\n      <td>[34, 63, 75, 67, 80, 77, 76, 14]</td>\n      <td>65</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9</td>\n      <td>Gosh, if only we could find Kat a boyfriend...</td>\n      <td>Let me see what I can do.</td>\n      <td>[38, 77, 81, 70, 12, 1, 71, 68, 1, 77, 76, 74,...</td>\n      <td>[43, 67, 82, 1, 75, 67, 1, 81, 67, 67, 1, 85, ...</td>\n      <td>46</td>\n      <td>25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.drop(['Unnamed: 0','question_as_int','answer_as_int','question_len','answer_len'],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:40:57.341833Z","iopub.execute_input":"2023-09-22T10:40:57.342181Z","iopub.status.idle":"2023-09-22T10:40:57.354441Z","shell.execute_reply.started":"2023-09-22T10:40:57.342141Z","shell.execute_reply":"2023-09-22T10:40:57.353695Z"},"editable":false,"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Info about data ","metadata":{"editable":false}},{"cell_type":"code","source":"print(df.shape)\nprint(\"=\"*60)\nprint(df.info())\nprint(\"=\"*60)\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:40:57.355911Z","iopub.execute_input":"2023-09-22T10:40:57.356197Z","iopub.status.idle":"2023-09-22T10:40:57.642296Z","shell.execute_reply.started":"2023-09-22T10:40:57.356170Z","shell.execute_reply":"2023-09-22T10:40:57.641566Z"},"editable":false,"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(139409, 2)\n============================================================\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 139409 entries, 0 to 139408\nData columns (total 2 columns):\n #   Column    Non-Null Count   Dtype \n---  ------    --------------   ----- \n 0   question  139409 non-null  object\n 1   answer    139409 non-null  object\ndtypes: object(2)\nmemory usage: 2.1+ MB\nNone\n============================================================\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"             question         answer\ncount          139409         139409\nunique         127480         127605\ntop     I don't know.  I don't know.\nfreq              203            276","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>139409</td>\n      <td>139409</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>127480</td>\n      <td>127605</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>I don't know.</td>\n      <td>I don't know.</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>203</td>\n      <td>276</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Clean Data","metadata":{"editable":false}},{"cell_type":"code","source":"df.drop_duplicates(subset=['question'],inplace=True)\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:40:57.644362Z","iopub.execute_input":"2023-09-22T10:40:57.644914Z","iopub.status.idle":"2023-09-22T10:40:57.895492Z","shell.execute_reply.started":"2023-09-22T10:40:57.644874Z","shell.execute_reply":"2023-09-22T10:40:57.894589Z"},"editable":false,"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                 question         answer\ncount                                              127480         127480\nunique                                             127480         117520\ntop     Make sure the Prince doesn't leave this room u...  I don't know.\nfreq                                                    1            225","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>127480</td>\n      <td>127480</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>127480</td>\n      <td>117520</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>Make sure the Prince doesn't leave this room u...</td>\n      <td>I don't know.</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>225</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(df.isnull().sum())\nprint('\\n')\nprint(df.isnull().any())","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:40:57.896896Z","iopub.execute_input":"2023-09-22T10:40:57.897262Z","iopub.status.idle":"2023-09-22T10:40:57.952929Z","shell.execute_reply.started":"2023-09-22T10:40:57.897222Z","shell.execute_reply":"2023-09-22T10:40:57.951931Z"},"editable":false,"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"question    0\nanswer      0\ndtype: int64\n\n\nquestion    False\nanswer      False\ndtype: bool\n","output_type":"stream"}]},{"cell_type":"code","source":"df.loc[55:60,:]","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:40:57.954173Z","iopub.execute_input":"2023-09-22T10:40:57.954562Z","iopub.status.idle":"2023-09-22T10:40:57.971199Z","shell.execute_reply.started":"2023-09-22T10:40:57.954531Z","shell.execute_reply":"2023-09-22T10:40:57.970525Z"},"editable":false,"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                             question  \\\n55  No! You're not dating until your sister starts...   \n56                   What if she never starts dating?   \n57  Then neither will you.  And I'll get to sleep ...   \n58                      But she doesn't want to date.   \n59                                        Daddy, I --   \n60                            And where're you going?   \n\n                                               answer  \n55                   What if she never starts dating?  \n56  Then neither will you.  And I'll get to sleep ...  \n57        But it's not fair -- she's a mutant, Daddy!  \n58                                   Exactly my point  \n59                            And where're you going?  \n60  If you must know, we were attempting to go to ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>55</th>\n      <td>No! You're not dating until your sister starts...</td>\n      <td>What if she never starts dating?</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>What if she never starts dating?</td>\n      <td>Then neither will you.  And I'll get to sleep ...</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>Then neither will you.  And I'll get to sleep ...</td>\n      <td>But it's not fair -- she's a mutant, Daddy!</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>But she doesn't want to date.</td>\n      <td>Exactly my point</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>Daddy, I --</td>\n      <td>And where're you going?</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>And where're you going?</td>\n      <td>If you must know, we were attempting to go to ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\ncontractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\", \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\ndef clean_text(text):\n    text = text.lower()\n    text = ' '.join([contractions[word] if word in contractions else word for word in text.split()])\n    text = re.sub(r'[^a-zA-Z0-9]',' ',text)\n    text = re.sub(r'\\d+', ' ', text)\n    txt = re.sub(r\"[^\\w\\s]\", \"\", text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:40:57.972816Z","iopub.execute_input":"2023-09-22T10:40:57.973341Z","iopub.status.idle":"2023-09-22T10:40:57.994733Z","shell.execute_reply.started":"2023-09-22T10:40:57.973304Z","shell.execute_reply":"2023-09-22T10:40:57.993912Z"},"editable":false,"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df['encoder_input']=df['question'].apply(clean_text)\ndf['decoder_input']=\"<sos> \" + df['answer'].apply(clean_text)\ndf['decoder_label'] = df['answer'].apply(clean_text) + ' eo>'\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:40:57.996010Z","iopub.execute_input":"2023-09-22T10:40:57.996437Z","iopub.status.idle":"2023-09-22T10:41:03.351295Z","shell.execute_reply.started":"2023-09-22T10:40:57.996398Z","shell.execute_reply":"2023-09-22T10:41:03.350385Z"},"editable":false,"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                            question  \\\n0  Well, I thought we'd start with pronunciation,...   \n1  Not the hacking and gagging and spitting part....   \n2  You're asking me out.  That's so cute. What's ...   \n3  No, no, it's my fault -- we didn't have a prop...   \n4     Gosh, if only we could find Kat a boyfriend...   \n\n                                              answer  \\\n0  Not the hacking and gagging and spitting part....   \n1  Okay... then how 'bout we try out some French ...   \n2                                         Forget it.   \n3                                           Cameron.   \n4                          Let me see what I can do.   \n\n                                       encoder_input  \\\n0  well  i thought we would start with pronunciat...   \n1  not the hacking and gagging and spitting part ...   \n2  you are asking me out  that is so cute  what i...   \n3  no  no  it is my fault    we did not have a pr...   \n4     gosh  if only we could find kat a boyfriend      \n\n                                       decoder_input  \\\n0  <sos> not the hacking and gagging and spitting...   \n1  <sos> okay    then how  bout we try out some f...   \n2                                   <sos> forget it    \n3                                     <sos> cameron    \n4                    <sos> let me see what i can do    \n\n                                       decoder_label  \n0  not the hacking and gagging and spitting part ...  \n1  okay    then how  bout we try out some french ...  \n2                                     forget it  eo>  \n3                                       cameron  eo>  \n4                      let me see what i can do  eo>  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n      <th>encoder_input</th>\n      <th>decoder_input</th>\n      <th>decoder_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Well, I thought we'd start with pronunciation,...</td>\n      <td>Not the hacking and gagging and spitting part....</td>\n      <td>well  i thought we would start with pronunciat...</td>\n      <td>&lt;sos&gt; not the hacking and gagging and spitting...</td>\n      <td>not the hacking and gagging and spitting part ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Not the hacking and gagging and spitting part....</td>\n      <td>Okay... then how 'bout we try out some French ...</td>\n      <td>not the hacking and gagging and spitting part ...</td>\n      <td>&lt;sos&gt; okay    then how  bout we try out some f...</td>\n      <td>okay    then how  bout we try out some french ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>You're asking me out.  That's so cute. What's ...</td>\n      <td>Forget it.</td>\n      <td>you are asking me out  that is so cute  what i...</td>\n      <td>&lt;sos&gt; forget it</td>\n      <td>forget it  eo&gt;</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>No, no, it's my fault -- we didn't have a prop...</td>\n      <td>Cameron.</td>\n      <td>no  no  it is my fault    we did not have a pr...</td>\n      <td>&lt;sos&gt; cameron</td>\n      <td>cameron  eo&gt;</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Gosh, if only we could find Kat a boyfriend...</td>\n      <td>Let me see what I can do.</td>\n      <td>gosh  if only we could find kat a boyfriend</td>\n      <td>&lt;sos&gt; let me see what i can do</td>\n      <td>let me see what i can do  eo&gt;</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"encoder_input = np.array(df.question)\ndecoder_input = np.array(df.decoder_input)\ndecoder_label = np.array(df.decoder_label)\n\nn_rows = df.shape[0]\nprint(f\"{n_rows} rows\")\n\nindices = np.arange(n_rows)\nnp.random.shuffle(indices)\n\nencoder_input = encoder_input[indices]\ndecoder_input = decoder_input[indices]\ndecoder_label = decoder_label[indices]\n\ntrain_size = 0.9\n\ntrain_encoder_input = encoder_input[:int(n_rows*train_size)]\ntrain_decoder_input = decoder_input[:int(n_rows*train_size)]\ntrain_decoder_label = decoder_label[:int(n_rows*train_size)]\n\ntest_encoder_input = encoder_input[int(n_rows*train_size):]\ntest_decoder_input = decoder_input[int(n_rows*train_size):]\ntest_decoder_label = decoder_label[int(n_rows*train_size):]\n\nprint(train_encoder_input.shape)\nprint(train_decoder_input.shape)\nprint(train_decoder_label.shape)\n\nprint(test_encoder_input.shape)\nprint(test_decoder_input.shape)\nprint(test_decoder_label.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:41:03.352809Z","iopub.execute_input":"2023-09-22T10:41:03.353162Z","iopub.status.idle":"2023-09-22T10:41:03.394606Z","shell.execute_reply.started":"2023-09-22T10:41:03.353119Z","shell.execute_reply":"2023-09-22T10:41:03.393579Z"},"editable":false,"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"127480 rows\n(114732,)\n(114732,)\n(114732,)\n(12748,)\n(12748,)\n(12748,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Tokens","metadata":{"editable":false}},{"cell_type":"code","source":"q_tok = Tokenizer()\nq_tok.fit_on_texts(train_encoder_input)\nprint(len(q_tok.word_counts))\n\na_tok = Tokenizer()\na_tok.fit_on_texts(train_decoder_input)\na_tok.fit_on_texts(train_decoder_label)\nprint(len(a_tok.word_counts))\n\ntrain_encoder_input = q_tok.texts_to_sequences(train_encoder_input)\ntest_encoder_input = q_tok.texts_to_sequences(test_encoder_input)\n\ntrain_decoder_input = a_tok.texts_to_sequences(train_decoder_input)\ntest_decoder_input = a_tok.texts_to_sequences(test_decoder_input)\n\ntrain_decoder_label = a_tok.texts_to_sequences(train_decoder_label)\ntest_decoder_label = a_tok.texts_to_sequences(test_decoder_label)\n\nquestion_word_size = len(q_tok.word_counts)\nquestion_vocab_size = question_word_size+1\n\nanswer_word_size = len(a_tok.word_counts)\nanswer_vocab_size = answer_word_size+1","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:41:03.398439Z","iopub.execute_input":"2023-09-22T10:41:03.398743Z","iopub.status.idle":"2023-09-22T10:41:14.937237Z","shell.execute_reply.started":"2023-09-22T10:41:03.398715Z","shell.execute_reply":"2023-09-22T10:41:14.936369Z"},"editable":false,"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"29962\n25683\n","output_type":"stream"}]},{"cell_type":"code","source":"question_lengths = [len(s) for s in train_encoder_input]\nprint(f\"maximum question sequence length >> {np.max(question_lengths)}\")\n\nanswer_lengths = [len(s) for s in train_decoder_input]\nprint(f\"maximum answer sequence length >> {np.max(answer_lengths)}\")\n\nplt.subplot(2,1,1)\nplt.hist(question_lengths,bins=50)\nplt.show()\n\nplt.subplot(2,1,2)\nplt.hist(answer_lengths,bins=50)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:41:14.938954Z","iopub.execute_input":"2023-09-22T10:41:14.939316Z","iopub.status.idle":"2023-09-22T10:41:17.248167Z","shell.execute_reply.started":"2023-09-22T10:41:14.939278Z","shell.execute_reply":"2023-09-22T10:41:17.247192Z"},"editable":false,"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"maximum question sequence length >> 25\nmaximum answer sequence length >> 31\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":"train_encoder_input = pad_sequences(train_encoder_input,padding='post')\ntrain_decoder_input = pad_sequences(train_decoder_input,padding='post')\ntrain_decoder_label = pad_sequences(train_decoder_label,padding='post')\n\nprint(train_encoder_input.shape)\nprint(train_decoder_input.shape)\nprint(train_decoder_label.shape)\n\nquestion_sequence_size = train_encoder_input.shape[1]\nanswer_sequence_size = train_decoder_input.shape[1]\n\ntest_encoder_input = pad_sequences(test_encoder_input,padding='post',maxlen=question_sequence_size)\ntest_decoder_input = pad_sequences(test_decoder_input,padding='post',maxlen=answer_sequence_size)\ntest_decoder_label = pad_sequences(test_decoder_label,padding='post',maxlen=answer_sequence_size)\n\nprint(test_encoder_input.shape)\nprint(test_decoder_input.shape)\nprint(test_decoder_label.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:41:17.252548Z","iopub.execute_input":"2023-09-22T10:41:17.254903Z","iopub.status.idle":"2023-09-22T10:41:20.580676Z","shell.execute_reply.started":"2023-09-22T10:41:17.254860Z","shell.execute_reply":"2023-09-22T10:41:20.579910Z"},"editable":false,"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"(114732, 25)\n(114732, 31)\n(114732, 31)\n(12748, 25)\n(12748, 31)\n(12748, 31)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Glove Emdding","metadata":{"editable":false}},{"cell_type":"code","source":"embedding_dict = dict()\n\nf = open(os.path.join('/kaggle/input/glove6b50dtxt/glove.6B.50d.txt'),encoding='utf-8')\n\nfor line in f:\n    tokens = line.split()\n    word = tokens[0]\n    vector = tokens[1:]\n    vector =  np.asarray(vector,dtype='float32')\n    embedding_dict[word] = vector\n    \nf.close()\n\nembedding_size = len(embedding_dict['world'])\nprint(f\"There are {len(embedding_dict)} embedding vectors in total\")\nprint(f\"The size of embedding vector here >> {embedding_size}\")\n\nquestion_embedding_matrix =  np.zeros((question_vocab_size,embedding_size))\nfor word,idx in q_tok.word_index.items():\n    if idx <= question_word_size:\n        vector = embedding_dict.get(word)\n        if vector is not None:\n            question_embedding_matrix[idx] = np.asarray(vector,dtype='float32')\n\nanswer_embedding_matrix =  np.zeros((answer_vocab_size,embedding_size))\nfor word,idx in q_tok.word_index.items():\n    if idx <= answer_word_size:\n        vector = embedding_dict.get(word)\n        if vector is not None:\n            answer_embedding_matrix[idx] = np.asarray(vector,dtype='float32')","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:41:20.582591Z","iopub.execute_input":"2023-09-22T10:41:20.582960Z","iopub.status.idle":"2023-09-22T10:41:30.511294Z","shell.execute_reply.started":"2023-09-22T10:41:20.582920Z","shell.execute_reply":"2023-09-22T10:41:30.510308Z"},"editable":false,"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"There are 400000 embedding vectors in total\nThe size of embedding vector here >> 50\n","output_type":"stream"}]},{"cell_type":"code","source":"def seq2question(encoder_input):\n    ret=[q_tok.index_word[idx] for idx in encoder_input if idx != 0]\n    return ' '.join(ret)\n\ndef seq2answer(decoder_input):\n    ret = []\n    for idx in decoder_input:\n        if idx != 0:\n            if a_tok.index_word[idx] != 'sos' and a_tok.index_word[idx] != 'eos':\n                ret.append(a_tok.index_word[idx])\n                \n    return ' '.join(ret)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:41:30.512704Z","iopub.execute_input":"2023-09-22T10:41:30.513052Z","iopub.status.idle":"2023-09-22T10:41:30.520312Z","shell.execute_reply.started":"2023-09-22T10:41:30.513013Z","shell.execute_reply":"2023-09-22T10:41:30.519307Z"},"editable":false,"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Attention\n","metadata":{"editable":false}},{"cell_type":"code","source":"import tensorflow\nfrom tensorflow.keras.layers import Attention","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:41:30.522031Z","iopub.execute_input":"2023-09-22T10:41:30.522523Z","iopub.status.idle":"2023-09-22T10:41:30.530283Z","shell.execute_reply.started":"2023-09-22T10:41:30.522484Z","shell.execute_reply":"2023-09-22T10:41:30.529356Z"},"editable":false,"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Model ","metadata":{"editable":false}},{"cell_type":"code","source":"#trainer model\n\nhidden_size = 256\n\n#encoder part start\nencoder_input = Input(shape=[question_sequence_size])\n# encoder_embedding = Embedding(question_vocab_size,embedding_size,mask_zero=True,trainable=False,weights=[question_embedding_matrix])\nencoder_embedding = Embedding(question_vocab_size,embedding_size,mask_zero=True)\nencoder_embedded = encoder_embedding(encoder_input)\n\nlstm1 = LSTM(hidden_size,return_sequences=True,return_state=True,dropout=0.3,recurrent_dropout=0.3)\nencoder_output1,_,_= lstm1(encoder_embedded)\nlstm2 = LSTM(hidden_size,return_sequences=True,return_state=True,dropout=0.3,recurrent_dropout=0.3)\nencoder_output2,_,_ = lstm2(encoder_output1)\nlstm3 = LSTM(hidden_size,return_sequences=True,return_state=True,dropout=0.3,recurrent_dropout=0.3)\nencoder_output3,encoder_h3,encoder_c3= lstm3(encoder_output2)\n#encoder part done\n\n#decoder part start\ndecoder_input = Input(shape=(None,))\n# decoder_embedding = Embedding(answer_vocab_size,embedding_size,mask_zero=True,trainable=False,weights=[answer_embedding_matrix])\ndecoder_embedding = Embedding(answer_vocab_size,embedding_size,mask_zero=True)\ndecoder_embedded = decoder_embedding(decoder_input)\n\ndecoder_lstm = LSTM(hidden_size,return_sequences=True,return_state=True)\ndecoder_output,_,_ = decoder_lstm(decoder_embedded,initial_state=[encoder_h3,encoder_c3])\n\n#Attention layer (query,value)\nattn_layer = Attention()\nattention_context = attn_layer([decoder_output,encoder_output3])\n\ndecoder_output = Concatenate(axis=-1)([decoder_output,attention_context])\n\ndense1 = Dense(512,activation='relu')\ndecoder_output = dense1(decoder_output)\n\ndecoder_softmax = Dense(answer_vocab_size,activation='softmax')\ndecoder_output = decoder_softmax(decoder_output)\n\ntrainer = Model([encoder_input,decoder_input],decoder_output)\nloss = tensorflow.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\ntrainer.compile(loss=loss,optimizer='adam',metrics=['accuracy'])\ntrainer.summary()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:41:30.532235Z","iopub.execute_input":"2023-09-22T10:41:30.532695Z","iopub.status.idle":"2023-09-22T10:41:34.064085Z","shell.execute_reply.started":"2023-09-22T10:41:30.532599Z","shell.execute_reply":"2023-09-22T10:41:34.063281Z"},"editable":false,"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 25)]         0                                            \n__________________________________________________________________________________________________\nembedding (Embedding)           (None, 25, 50)       1498150     input_1[0][0]                    \n__________________________________________________________________________________________________\nlstm (LSTM)                     [(None, 25, 256), (N 314368      embedding[0][0]                  \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            [(None, None)]       0                                            \n__________________________________________________________________________________________________\nlstm_1 (LSTM)                   [(None, 25, 256), (N 525312      lstm[0][0]                       \n__________________________________________________________________________________________________\nembedding_1 (Embedding)         (None, None, 50)     1284200     input_2[0][0]                    \n__________________________________________________________________________________________________\nlstm_2 (LSTM)                   [(None, 25, 256), (N 525312      lstm_1[0][0]                     \n__________________________________________________________________________________________________\nlstm_3 (LSTM)                   [(None, None, 256),  314368      embedding_1[0][0]                \n                                                                 lstm_2[0][1]                     \n                                                                 lstm_2[0][2]                     \n__________________________________________________________________________________________________\nattention (Attention)           (None, None, 256)    0           lstm_3[0][0]                     \n                                                                 lstm_2[0][0]                     \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, None, 512)    0           lstm_3[0][0]                     \n                                                                 attention[0][0]                  \n__________________________________________________________________________________________________\ndense (Dense)                   (None, None, 512)    262656      concatenate[0][0]                \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, None, 25684)  13175892    dense[0][0]                      \n==================================================================================================\nTotal params: 17,900,258\nTrainable params: 17,900,258\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"train_hist = trainer.fit([train_encoder_input,train_decoder_input],train_decoder_label,epochs=200,validation_split=0.1,batch_size=512)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:41:34.067352Z","iopub.execute_input":"2023-09-22T10:41:34.067648Z","iopub.status.idle":"2023-09-22T13:31:36.847088Z","shell.execute_reply.started":"2023-09-22T10:41:34.067619Z","shell.execute_reply":"2023-09-22T13:31:36.846175Z"},"editable":false,"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch 1/45\n404/404 [==============================] - 242s 566ms/step - loss: 1.8840 - accuracy: 0.1248 - val_loss: 1.5505 - val_accuracy: 0.1653\nEpoch 2/45\n404/404 [==============================] - 226s 561ms/step - loss: 1.4942 - accuracy: 0.1822 - val_loss: 1.4541 - val_accuracy: 0.2088\nEpoch 3/45\n404/404 [==============================] - 227s 562ms/step - loss: 1.4048 - accuracy: 0.2136 - val_loss: 1.4227 - val_accuracy: 0.2174\nEpoch 4/45\n404/404 [==============================] - 227s 561ms/step - loss: 1.3603 - accuracy: 0.2207 - val_loss: 1.4065 - val_accuracy: 0.2230\nEpoch 5/45\n404/404 [==============================] - 227s 562ms/step - loss: 1.3273 - accuracy: 0.2273 - val_loss: 1.3983 - val_accuracy: 0.2265\nEpoch 6/45\n404/404 [==============================] - 227s 561ms/step - loss: 1.2930 - accuracy: 0.2323 - val_loss: 1.3950 - val_accuracy: 0.2290\nEpoch 7/45\n404/404 [==============================] - 228s 564ms/step - loss: 1.2712 - accuracy: 0.2371 - val_loss: 1.3965 - val_accuracy: 0.2321\nEpoch 8/45\n404/404 [==============================] - 226s 561ms/step - loss: 1.2416 - accuracy: 0.2401 - val_loss: 1.4008 - val_accuracy: 0.2347\nEpoch 9/45\n404/404 [==============================] - 226s 561ms/step - loss: 1.2167 - accuracy: 0.2447 - val_loss: 1.4096 - val_accuracy: 0.2361\nEpoch 10/45\n404/404 [==============================] - 228s 564ms/step - loss: 1.1943 - accuracy: 0.2473 - val_loss: 1.4229 - val_accuracy: 0.2379\nEpoch 11/45\n404/404 [==============================] - 229s 566ms/step - loss: 1.1718 - accuracy: 0.2515 - val_loss: 1.4369 - val_accuracy: 0.2373\nEpoch 12/45\n404/404 [==============================] - 228s 564ms/step - loss: 1.1461 - accuracy: 0.2574 - val_loss: 1.4528 - val_accuracy: 0.2366\nEpoch 13/45\n404/404 [==============================] - 226s 559ms/step - loss: 1.1233 - accuracy: 0.2632 - val_loss: 1.4722 - val_accuracy: 0.2386\nEpoch 14/45\n404/404 [==============================] - 225s 558ms/step - loss: 1.1002 - accuracy: 0.2699 - val_loss: 1.4920 - val_accuracy: 0.2393\nEpoch 15/45\n404/404 [==============================] - 228s 563ms/step - loss: 1.0821 - accuracy: 0.2751 - val_loss: 1.5121 - val_accuracy: 0.2363\nEpoch 16/45\n404/404 [==============================] - 227s 563ms/step - loss: 1.0658 - accuracy: 0.2818 - val_loss: 1.5345 - val_accuracy: 0.2386\nEpoch 17/45\n404/404 [==============================] - 227s 562ms/step - loss: 1.0484 - accuracy: 0.2879 - val_loss: 1.5563 - val_accuracy: 0.2380\nEpoch 18/45\n404/404 [==============================] - 226s 559ms/step - loss: 1.0327 - accuracy: 0.2934 - val_loss: 1.5734 - val_accuracy: 0.2379\nEpoch 19/45\n404/404 [==============================] - 226s 560ms/step - loss: 1.0155 - accuracy: 0.2984 - val_loss: 1.5943 - val_accuracy: 0.2379\nEpoch 20/45\n404/404 [==============================] - 227s 562ms/step - loss: 1.0044 - accuracy: 0.3043 - val_loss: 1.6155 - val_accuracy: 0.2371\nEpoch 21/45\n404/404 [==============================] - 227s 562ms/step - loss: 0.9933 - accuracy: 0.3085 - val_loss: 1.6348 - val_accuracy: 0.2356\nEpoch 22/45\n404/404 [==============================] - 226s 559ms/step - loss: 0.9829 - accuracy: 0.3127 - val_loss: 1.6583 - val_accuracy: 0.2360\nEpoch 23/45\n404/404 [==============================] - 228s 563ms/step - loss: 0.9676 - accuracy: 0.3184 - val_loss: 1.6776 - val_accuracy: 0.2357\nEpoch 24/45\n404/404 [==============================] - 226s 560ms/step - loss: 0.9555 - accuracy: 0.3232 - val_loss: 1.6976 - val_accuracy: 0.2346\nEpoch 25/45\n404/404 [==============================] - 226s 559ms/step - loss: 0.9489 - accuracy: 0.3262 - val_loss: 1.7141 - val_accuracy: 0.2351\nEpoch 26/45\n404/404 [==============================] - 226s 559ms/step - loss: 0.9346 - accuracy: 0.3327 - val_loss: 1.7327 - val_accuracy: 0.2326\nEpoch 27/45\n404/404 [==============================] - 226s 560ms/step - loss: 0.9315 - accuracy: 0.3358 - val_loss: 1.7570 - val_accuracy: 0.2322\nEpoch 28/45\n404/404 [==============================] - 226s 561ms/step - loss: 0.9167 - accuracy: 0.3397 - val_loss: 1.7793 - val_accuracy: 0.2327\nEpoch 29/45\n404/404 [==============================] - 225s 556ms/step - loss: 0.9094 - accuracy: 0.3439 - val_loss: 1.7918 - val_accuracy: 0.2315\nEpoch 30/45\n404/404 [==============================] - 226s 559ms/step - loss: 0.9002 - accuracy: 0.3482 - val_loss: 1.8100 - val_accuracy: 0.2292\nEpoch 31/45\n404/404 [==============================] - 226s 559ms/step - loss: 0.8918 - accuracy: 0.3512 - val_loss: 1.8318 - val_accuracy: 0.2286\nEpoch 32/45\n404/404 [==============================] - 226s 559ms/step - loss: 0.8836 - accuracy: 0.3545 - val_loss: 1.8483 - val_accuracy: 0.2283\nEpoch 33/45\n404/404 [==============================] - 225s 557ms/step - loss: 0.8743 - accuracy: 0.3598 - val_loss: 1.8692 - val_accuracy: 0.2262\nEpoch 34/45\n404/404 [==============================] - 226s 559ms/step - loss: 0.8687 - accuracy: 0.3639 - val_loss: 1.8873 - val_accuracy: 0.2278\nEpoch 35/45\n404/404 [==============================] - 227s 562ms/step - loss: 0.8571 - accuracy: 0.3668 - val_loss: 1.9060 - val_accuracy: 0.2266\nEpoch 36/45\n404/404 [==============================] - 227s 562ms/step - loss: 0.8511 - accuracy: 0.3703 - val_loss: 1.9166 - val_accuracy: 0.2265\nEpoch 37/45\n404/404 [==============================] - 226s 559ms/step - loss: 0.8473 - accuracy: 0.3749 - val_loss: 1.9327 - val_accuracy: 0.2262\nEpoch 38/45\n404/404 [==============================] - 225s 558ms/step - loss: 0.8362 - accuracy: 0.3772 - val_loss: 1.9555 - val_accuracy: 0.2253\nEpoch 39/45\n404/404 [==============================] - 226s 560ms/step - loss: 0.8308 - accuracy: 0.3813 - val_loss: 1.9714 - val_accuracy: 0.2232\nEpoch 40/45\n404/404 [==============================] - 226s 559ms/step - loss: 0.8272 - accuracy: 0.3838 - val_loss: 1.9840 - val_accuracy: 0.2236\nEpoch 41/45\n404/404 [==============================] - 226s 560ms/step - loss: 0.8191 - accuracy: 0.3875 - val_loss: 2.0004 - val_accuracy: 0.2245\nEpoch 42/45\n404/404 [==============================] - 226s 558ms/step - loss: 0.8125 - accuracy: 0.3913 - val_loss: 2.0205 - val_accuracy: 0.2215\nEpoch 43/45\n404/404 [==============================] - 225s 557ms/step - loss: 0.8070 - accuracy: 0.3942 - val_loss: 2.0410 - val_accuracy: 0.2224\nEpoch 44/45\n404/404 [==============================] - 225s 558ms/step - loss: 0.8001 - accuracy: 0.3981 - val_loss: 2.0475 - val_accuracy: 0.2210\nEpoch 45/45\n404/404 [==============================] - 226s 559ms/step - loss: 0.7931 - accuracy: 0.4006 - val_loss: 2.0756 - val_accuracy: 0.2208\n","output_type":"stream"}]},{"cell_type":"code","source":"#generator model\ngen_encoder = Model(encoder_input,[encoder_output3,encoder_h3,encoder_c3])\n\ngen_decoder_value_input = Input(shape=(question_sequence_size,hidden_size))\ngen_decoder_h_input = Input(shape=[hidden_size])\ngen_decoder_c_input = Input(shape=[hidden_size])\n\ngen_decoder_embedded = decoder_embedding(decoder_input)\ngen_decoder_output,gen_decoder_h,gen_decoder_c = decoder_lstm(gen_decoder_embedded,initial_state=[gen_decoder_h_input,gen_decoder_c_input])\n\n#attention([querys,values])\ngen_attention_context = attn_layer([gen_decoder_output,gen_decoder_value_input])\ngen_decoder_output = Concatenate(axis=-1)([gen_decoder_output,gen_attention_context])\n\ngen_decoder_output = dense1(gen_decoder_output)\ngen_decoder_output = decoder_softmax(gen_decoder_output)\n\ngen_decoder = Model([decoder_input]+[gen_decoder_value_input,gen_decoder_h_input,gen_decoder_c_input],[gen_decoder_output]+[gen_decoder_h,gen_decoder_c])\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-22T13:31:36.849802Z","iopub.execute_input":"2023-09-22T13:31:36.850344Z","iopub.status.idle":"2023-09-22T13:31:37.622519Z","shell.execute_reply.started":"2023-09-22T13:31:36.850303Z","shell.execute_reply":"2023-09-22T13:31:37.621728Z"},"editable":false,"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def generate_from_input(encoder_input):\n    values,h,c = gen_encoder.predict(encoder_input)\n    \n    decoder_seq = np.zeros((1,1))\n    decoder_seq[0,0] = a_tok.word_index['sos']\n    \n    generated_sent = ''\n    stop_condition= False\n    \n    while not stop_condition:\n        output,h_state,c_state = gen_decoder.predict([decoder_seq]+[values,h,c])\n        sampled_index = np.argmax(output[0,-1,:])\n        sampled_word = a_tok.index_word[sampled_index]\n        \n        if sampled_word != 'eos':\n            generated_sent = generated_sent + sampled_word + ' '\n        \n        if sampled_word == 'eos' or len(generated_sent) >= answer_sequence_size:\n            stop_condition=True\n        \n        decoder_seq = np.zeros((1,1))\n        decoder_seq[0,0] = sampled_index\n        h,c = h_state,c_state\n        \n    return generated_sent.strip()\n\nprint(generate_from_input(train_encoder_input[24].reshape(1,question_sequence_size,-1)))\nprint(generate_from_input(train_encoder_input[1021].reshape(1,question_sequence_size,-1)))\nprint(generate_from_input(train_encoder_input[3001].reshape(1,question_sequence_size,-1)))","metadata":{"execution":{"iopub.status.busy":"2023-09-22T13:31:37.625994Z","iopub.execute_input":"2023-09-22T13:31:37.626284Z","iopub.status.idle":"2023-09-22T13:31:40.845873Z","shell.execute_reply.started":"2023-09-22T13:31:37.626251Z","shell.execute_reply":"2023-09-22T13:31:40.844839Z"},"editable":false,"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"no i am not eo eo eo eo eo sports\ni am not sure i am not eo eo eo\ni am not sure i am not eo eo eo\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Test ","metadata":{"editable":false}},{"cell_type":"code","source":"#results on train dataset\nsample_indices= [5,26,7,11,735,662,115,321]\n\nfor idx in sample_indices:\n    generated_sent = generate_from_input(train_encoder_input[idx:idx+1])\n    print(f\"Question >> {seq2question(train_encoder_input[idx])}\")\n    print(f\"Answer(Generated) >> {generated_sent}\")\n    print(f\"Answer(Label) >> {seq2answer(train_decoder_input[idx])}\")\n    print(\"=\"*45)\n    print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-09-22T13:31:40.847106Z","iopub.execute_input":"2023-09-22T13:31:40.847459Z","iopub.status.idle":"2023-09-22T13:31:44.754600Z","shell.execute_reply.started":"2023-09-22T13:31:40.847417Z","shell.execute_reply":"2023-09-22T13:31:44.753588Z"},"editable":false,"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Question >> he's getting up\nAnswer(Generated) >> i am not sure i am not eo eo eo\nAnswer(Label) >> you cannot leave me then can you\n=============================================\n\n\nQuestion >> it is now we're locked in\nAnswer(Generated) >> yeah i know what i am doing eo\nAnswer(Label) >> starck give me a read\n=============================================\n\n\nQuestion >> i did what\nAnswer(Generated) >> i think you are the maxine winged\nAnswer(Label) >> as a matter of fact you came home without any clothes you were in your uh shorts yes sir\n=============================================\n\n\nQuestion >> no you'll be marked for death\nAnswer(Generated) >> no problem eo eo eo clyde boys\nAnswer(Label) >> let me die then\n=============================================\n\n\nQuestion >> i'm right behind you blue leader\nAnswer(Generated) >> i am not sure i am not going to\nAnswer(Label) >> what is that\n=============================================\n\n\nQuestion >> gee mom do you think maybe he's a diamond smuggler\nAnswer(Generated) >> i am not sure i am going to be\nAnswer(Label) >> come on darling we are going up to bed\n=============================================\n\n\nQuestion >> heavens look at that now\nAnswer(Generated) >> he is a little spoiled here eo\nAnswer(Label) >> i have seen it\n=============================================\n\n\nQuestion >> correct me if i'm wrong but i don't think so\nAnswer(Generated) >> i am not going to be here eo eo\nAnswer(Label) >> i will listen one more minute\n=============================================\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"#results on test dataset\nsample_indices= [159,29,44,33]\n\nfor idx in sample_indices:\n    generated_sent = generate_from_input(test_encoder_input[idx:idx+1])\n    print(f\"Question >> {seq2question(test_encoder_input[idx])}\")\n    print(f\"Answer(Generated) >> {generated_sent}\")\n    print(f\"Answer(Label) >> {seq2answer(test_decoder_input[idx])}\")\n    print(\"=\"*45)\n    print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-09-22T13:31:44.755877Z","iopub.execute_input":"2023-09-22T13:31:44.756235Z","iopub.status.idle":"2023-09-22T13:31:46.987265Z","shell.execute_reply.started":"2023-09-22T13:31:44.756198Z","shell.execute_reply":"2023-09-22T13:31:46.986172Z"},"editable":false,"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Question >> don't do this send her a card something\nAnswer(Generated) >> i am not interested in th eo i\nAnswer(Label) >> we will make it\n=============================================\n\n\nQuestion >> when i was very young\nAnswer(Generated) >> i do not know eo fermented grapes\nAnswer(Label) >> it seems like such a complicated game\n=============================================\n\n\nQuestion >> i've got a responsibility here i can't let everybody grab free drinks\nAnswer(Generated) >> i am not going to be long eo eo\nAnswer(Label) >> what responsibility you are closing the fucking store to play hockey\n=============================================\n\n\nQuestion >> it's amazing\nAnswer(Generated) >> i am not sure i am not afraid of\nAnswer(Label) >> i ve acted out my life on stages with ten thousand people watching\n=============================================\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"editable":false},"execution_count":null,"outputs":[]}]}